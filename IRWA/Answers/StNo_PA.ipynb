{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ce9ee0b-6190-4899-9a88-99c6c0583b51",
   "metadata": {},
   "source": [
    "# Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3965d23a-2c5c-45bc-b1ce-d70e0567c072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Group1.txt', 'Group2.txt', 'Group3.txt', 'Group4.txt', 'Group5.txt']\n",
      "<_io.TextIOWrapper name='C:\\\\Users\\\\vihar\\\\Desktop\\\\SLIIT-Y3S1\\\\IRWA\\\\Practical Assiignment/groups/Group1.txt' mode='r' encoding='cp1252'>\n",
      "<_io.TextIOWrapper name='C:\\\\Users\\\\vihar\\\\Desktop\\\\SLIIT-Y3S1\\\\IRWA\\\\Practical Assiignment/groups/Group2.txt' mode='r' encoding='cp1252'>\n",
      "<_io.TextIOWrapper name='C:\\\\Users\\\\vihar\\\\Desktop\\\\SLIIT-Y3S1\\\\IRWA\\\\Practical Assiignment/groups/Group3.txt' mode='r' encoding='cp1252'>\n",
      "<_io.TextIOWrapper name='C:\\\\Users\\\\vihar\\\\Desktop\\\\SLIIT-Y3S1\\\\IRWA\\\\Practical Assiignment/groups/Group4.txt' mode='r' encoding='cp1252'>\n",
      "<_io.TextIOWrapper name='C:\\\\Users\\\\vihar\\\\Desktop\\\\SLIIT-Y3S1\\\\IRWA\\\\Practical Assiignment/groups/Group5.txt' mode='r' encoding='cp1252'>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Initialize the dictionary for the inverted index\n",
    "dictionary = dict()\n",
    "\n",
    "# Get the current directory and add the path to the directory containing the files\n",
    "directory = os.getcwd() + '/groups'\n",
    "\n",
    "# Store a list of all files present in the directory into the files variable\n",
    "files = os.listdir(directory)\n",
    "print(files)  # Check files are available in the path (directory)\n",
    "\n",
    "# Open and read each document (files) to create inverted indexes\n",
    "for file in files:\n",
    "    with open(directory + '/' + file, 'r') as f:\n",
    "        print(f)  # Access each document one by one\n",
    "        words = f.read().lower().split()  # Lowercase all sentences and tokenize\n",
    "        #print(words)  # Check the tokenized words\n",
    "\n",
    "        # For each word in the document, update the inverted index\n",
    "        for word in words:\n",
    "            if word not in dictionary:\n",
    "                # If the word is not already in the dictionary, add it\n",
    "                dictionary[word] = [file]\n",
    "            else:\n",
    "                # If the word is already in the dictionary, append the document to the list\n",
    "                dictionary[word].append(file)\n",
    "\n",
    "# Print the final inverted index\n",
    "#print(dictionary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bd5aec-e7d1-4444-8f9a-108dd0c65864",
   "metadata": {},
   "source": [
    "### (01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "230bfd5d-fd26-4007-9014-a27f45c9a653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Students who are in both Group 2 and Group 3 but not in Group 5:\n",
      "{'Peter'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current directory and add the path to the directory containing the files\n",
    "directory = os.getcwd() + '/groups'\n",
    "\n",
    "# Load the names from each group file\n",
    "with open(directory + '/Group2.txt') as f:\n",
    "    group2 = set(f.read().split(', '))\n",
    "\n",
    "with open(directory + '/Group3.txt') as f:\n",
    "    group3 = set(f.read().split(', '))\n",
    "\n",
    "with open(directory + '/Group5.txt') as f:\n",
    "    group5 = set(f.read().split(', '))\n",
    "\n",
    "# Find students who belong to both Group 2 and Group 3\n",
    "intersection_2_3 = group2.intersection(group3)\n",
    "\n",
    "# Exclude students in Group 5\n",
    "result = intersection_2_3.difference(group5)\n",
    "\n",
    "# Print the result\n",
    "print(\"Students who are in both Group 2 and Group 3 but not in Group 5:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cc83e5-e541-43bb-bb04-352fcc768210",
   "metadata": {},
   "source": [
    "### (02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86d012e0-e745-4022-a93f-7dca62e23a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Students who are in both Group 1 and Group 4 but not in Group 5:\n",
      "{'Ursula', 'Yvonne', 'George'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current directory and add the path to the directory containing the files\n",
    "directory = os.getcwd() + '/groups'\n",
    "\n",
    "# Load the names from each group file\n",
    "with open(directory + '/Group1.txt') as f:\n",
    "    group1 = set(f.read().split(', '))\n",
    "\n",
    "with open(directory + '/Group4.txt') as f:\n",
    "    group4 = set(f.read().split(', '))\n",
    "\n",
    "with open(directory + '/Group5.txt') as f:\n",
    "    group5 = set(f.read().split(', '))\n",
    "\n",
    "# Find students who belong to both Group 1 and Group 4\n",
    "intersection_1_4 = group1.intersection(group4)\n",
    "\n",
    "# Exclude students in Group 5\n",
    "result = intersection_1_4.difference(group5)\n",
    "\n",
    "# Print the result\n",
    "print(\"Students who are in both Group 1 and Group 4 but not in Group 5:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df41ee90-f9cb-46f9-bcd1-48f35899bf36",
   "metadata": {},
   "source": [
    "### (03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7779b89e-b3bd-4bce-b2fe-bc53a55d0f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New group(G) combining results from Task 1 and Task 2:\n",
      "{'Yvonne', 'Ursula', 'Peter', 'George'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current directory and add the path to the directory containing the files\n",
    "directory = os.getcwd() + '/groups'\n",
    "\n",
    "# Load the names from each group file\n",
    "with open(directory + '/Group1.txt') as f:\n",
    "    group1 = set(f.read().split(', '))\n",
    "\n",
    "with open(directory + '/Group2.txt') as f:\n",
    "    group2 = set(f.read().split(', '))\n",
    "\n",
    "with open(directory + '/Group3.txt') as f:\n",
    "    group3 = set(f.read().split(', '))\n",
    "\n",
    "with open(directory + '/Group4.txt') as f:\n",
    "    group4 = set(f.read().split(', '))\n",
    "\n",
    "with open(directory + '/Group5.txt') as f:\n",
    "    group5 = set(f.read().split(', '))\n",
    "\n",
    "# Task 1: Find students who belong to both Group 2 and Group 3 but not in Group 5\n",
    "intersection_2_3 = group2.intersection(group3)\n",
    "task1_result = intersection_2_3.difference(group5)\n",
    "\n",
    "# Task 2: Find students who belong to both Group 1 and Group 4 but not in Group 5\n",
    "intersection_1_4 = group1.intersection(group4)\n",
    "task2_result = intersection_1_4.difference(group5)\n",
    "\n",
    "# Combine the results from both tasks to form a new group\n",
    "new_group = task1_result.union(task2_result)\n",
    "\n",
    "# Print the result\n",
    "print(\"New group(G) combining results from Task 1 and Task 2:\")\n",
    "print(new_group)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba2ecef-5f97-411c-be26-b281460fd98e",
   "metadata": {},
   "source": [
    "### (04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "020066f1-f1f5-4f87-9c64-772d160ac2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverted Index (Student -> Competitions):\n",
      "Peter: {'Drama', 'Singing', 'Drawing'}\n",
      "David: {'Drama', 'Singing', 'Drawing', 'Dancing'}\n",
      "Jane: {'Drama', 'Singing', 'Drawing', 'Dancing'}\n",
      "Kane: {'Drama', 'Singing', 'Dancing'}\n",
      "Sam: {'Drawing', 'Dancing'}\n",
      "Patrick: {'Dancing'}\n",
      "Anne: {'Drama', 'Drawing'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "import os\n",
    "\n",
    "# Check if required NLTK packages are already installed\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('taggers/averaged_perceptron_tagger')\n",
    "except LookupError:\n",
    "    nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Function to process the text, extract names and map them to competitions\n",
    "def build_inverted_index(file_name, competition_name, inverted_index):\n",
    "    with open(file_name, 'r') as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    # Tokenize the text into words and apply POS tagging\n",
    "    words = nltk.word_tokenize(text)\n",
    "    tagged_words = nltk.pos_tag(words)\n",
    "    \n",
    "    # Extract proper nouns (NNP) as potential student names\n",
    "    student_names = {word for word, pos in tagged_words if pos == 'NNP'}\n",
    "    \n",
    "    # For each student name, map it to the current competition\n",
    "    for name in student_names:\n",
    "        inverted_index[name].add(competition_name)\n",
    "\n",
    "# Get the current directory and add the path to the directory containing the files\n",
    "directory = os.getcwd() + '/competitions'\n",
    "\n",
    "# Initialize the inverted index (default dictionary to hold sets of competition names)\n",
    "inverted_index = defaultdict(set)\n",
    "\n",
    "# Build the inverted index from all four competition files\n",
    "build_inverted_index(directory + '/Sing.txt', 'Singing', inverted_index)\n",
    "build_inverted_index(directory + '/Dance.txt', 'Dancing', inverted_index)\n",
    "build_inverted_index(directory + '/Draw.txt', 'Drawing', inverted_index)\n",
    "build_inverted_index(directory + '/Drama.txt', 'Drama', inverted_index)\n",
    "\n",
    "# Print the inverted index for debugging\n",
    "print(\"Inverted Index (Student -> Competitions):\")\n",
    "for student, competitions in inverted_index.items():\n",
    "    print(f\"{student}: {competitions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaae5e6c-6e8a-474d-a8ae-5d859ada6ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Competitions for students in Group H:\n",
      "Ursula is not participating in any competitions.\n",
      "Yvonne is not participating in any competitions.\n",
      "Peter is participating in: Drama, Singing, Drawing\n",
      "George is not participating in any competitions.\n"
     ]
    }
   ],
   "source": [
    "# (03) new group (Group H)\n",
    "group_h = {'Ursula', 'George', 'Peter', 'Yvonne'}\n",
    "\n",
    "# Find competitions for each student in Group H\n",
    "print(\"\\nCompetitions for students in Group H:\")\n",
    "for student in group_h:\n",
    "    competitions = inverted_index.get(student, set())\n",
    "    if competitions:\n",
    "        print(f\"{student} is participating in: {', '.join(competitions)}\")\n",
    "    else:\n",
    "        print(f\"{student} is not participating in any competitions.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c7452a-21e0-40dc-b3f5-9290e71db653",
   "metadata": {},
   "source": [
    "### (05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b3bdfae-cf61-431f-93d8-1d94f7522afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Competitions where students in Group H are not performing:\n",
      "{'Dancing'}\n",
      "\n",
      "Proper nouns in Dancing competition description:\n",
      "['Sam', 'Jane', 'Kane', 'David', 'Patrick']\n"
     ]
    }
   ],
   "source": [
    "# Function to process the text, extract names and map them to competitions\n",
    "def build_inverted_index(file_name, competition_name, inverted_index, descriptions):\n",
    "    with open(file_name, 'r') as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    # Tokenize the text into words and apply POS tagging\n",
    "    words = nltk.word_tokenize(text)\n",
    "    tagged_words = nltk.pos_tag(words)\n",
    "    \n",
    "    # Extract proper nouns (NNP) as potential student names\n",
    "    student_names = {word for word, pos in tagged_words if pos == 'NNP'}\n",
    "    \n",
    "    # For each student name, map it to the current competition\n",
    "    for name in student_names:\n",
    "        inverted_index[name].add(competition_name)\n",
    "    \n",
    "    # Store the competition description for later processing\n",
    "    descriptions[competition_name] = text\n",
    "\n",
    "# Get the current directory and add the path to the directory containing the files\n",
    "directory = os.getcwd() + '/competitions'\n",
    "\n",
    "# Initialize the inverted index (default dictionary to hold sets of competition names)\n",
    "inverted_index = defaultdict(set)\n",
    "descriptions = {}\n",
    "\n",
    "# Build the inverted index from all four competition files\n",
    "build_inverted_index(directory + '/Sing.txt', 'Singing', inverted_index, descriptions)\n",
    "build_inverted_index(directory + '/Dance.txt', 'Dancing', inverted_index, descriptions)\n",
    "build_inverted_index(directory + '/Draw.txt', 'Drawing', inverted_index, descriptions)\n",
    "build_inverted_index(directory + '/Drama.txt', 'Drama', inverted_index, descriptions)\n",
    "\n",
    "# List of students in Group H\n",
    "group_h = {'Ursula', 'George', 'Peter', 'Yvonne'}\n",
    "\n",
    "# Find competitions for each student in Group H\n",
    "group_h_competitions = set()\n",
    "for student in group_h:\n",
    "    competitions = inverted_index.get(student, set())\n",
    "    group_h_competitions.update(competitions)\n",
    "\n",
    "# All available competitions\n",
    "all_competitions = {'Singing', 'Dancing', 'Drawing', 'Drama'}\n",
    "\n",
    "# Competitions where Group H students are not performing\n",
    "not_performing_competitions = all_competitions - group_h_competitions\n",
    "\n",
    "print(\"Competitions where students in Group H are not performing:\")\n",
    "print(not_performing_competitions)\n",
    "\n",
    "# Function to extract proper nouns from a competition description\n",
    "def extract_proper_nouns(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    tagged_words = nltk.pos_tag(words)\n",
    "    \n",
    "    # Extract proper nouns (NNP)\n",
    "    proper_nouns = [word for word, pos in tagged_words if pos == 'NNP']\n",
    "    return proper_nouns\n",
    "\n",
    "# Find proper nouns in the descriptions of competitions where Group H students are not performing\n",
    "for competition in not_performing_competitions:\n",
    "    description = descriptions[competition]\n",
    "    proper_nouns = extract_proper_nouns(description)\n",
    "    print(f\"\\nProper nouns in {competition} competition description:\")\n",
    "    print(proper_nouns)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
